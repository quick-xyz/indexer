CONTEXT FOR CONTINUATION - DATABASE MIGRATION STRATEGY
I'm working on migrating my blockchain indexer's shared database but need a systematic approach rather than fixing issues one by one.
CURRENT SITUATION:

I have a large Alembic migration (d5c49de1c76d_update_schemas_for_pricing_service.py) that adds the price_vwap table and many other schema changes
The migration keeps failing on NOT NULL constraint violations because it's trying to add NOT NULL columns to tables with existing data
My DI container can't initialize because the code expects schema changes that haven't been applied yet (chicken-and-egg problem)
I have valuable data in my indexer database that I want to preserve, but I'm okay with resetting the shared database if needed

SPECIFIC ISSUES ENCOUNTERED:

Migration fails on address_type VARCHAR(50) NOT NULL being added to addresses table with existing data
Similar failures for timestamp columns (created_at, updated_at) being added as NOT NULL to multiple tables
Code expects models.target_asset column that doesn't exist until migration runs
Manual fixes create conflicts when migration tries to add the same columns

WHAT I NEED:
A systematic strategy that considers:

Option A: Fix the migration file itself to handle existing data properly (add columns as nullable first, populate them, then make NOT NULL)
Option B: Reset the shared database cleanly and start fresh (acceptable since it's not data-heavy)
Option C: Create a pre-migration script that prepares the data properly before running the migration

CONSTRAINTS:

Must preserve indexer database data (has lots of records)
Shared database can be reset if needed (not much critical data)
Need to avoid the reactive "fix each error as it comes" approach
Migration file is auto-generated by Alembic so editing it may not be ideal

ARCHITECTURE CONTEXT:

Dual database setup: shared database (indexer_shared) for infrastructure, indexer database (e.g., blub_test) for model-specific data
Using Alembic for shared database migrations
DI container system that validates schema on startup
Recent development added many new tables/columns for pricing service

Please help me choose the best systematic approach and create a comprehensive plan to execute it properly.